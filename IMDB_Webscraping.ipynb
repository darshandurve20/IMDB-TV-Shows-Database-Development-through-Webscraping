{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the html response from the 50 popular TV shows IMDB webpage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imdb.com/search/title?title_type=tv_series\"\n",
    "response = get(url)\n",
    "html_soup = bs(response.text ,'html.parser')\n",
    "id_check = html_soup.find(id =\"main\")\n",
    "tv_show_container = id_check.find_all(class_ =\"lister-item mode-advanced\")\n",
    "container = tv_show_container[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List to store scraped value data in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_show_names = []\n",
    "year_release = []\n",
    "imdb_ratings = []\n",
    "votes = []\n",
    "tv_show_description = []\n",
    "runtime = []\n",
    "genre = []\n",
    "star_cast = []\n",
    "title_Id = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping the data by looping through the webpage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for container in tv_show_container:\n",
    "\n",
    "    if container.find(\"div\", class_ = \"ratings-bar\") is not None:\n",
    "\n",
    "        name = container.h3.a.text\n",
    "        tv_show_names.append(name)\n",
    "\n",
    "        Id = container.img['data-tconst']\n",
    "        title_Id.append(Id)\n",
    "\n",
    "        release = container.find(\"span\", class_ = \"lister-item-year text-muted unbold\").text\n",
    "        year_release.append(release)\n",
    "\n",
    "        ratings = float(container.strong.text)\n",
    "        imdb_ratings.append(ratings)\n",
    "\n",
    "        vote = container.find(\"span\", attrs = {\"name\" :\"nv\"})['data-value']\n",
    "        votes.append(int(vote))\n",
    "\n",
    "        run = container.find(\"span\", class_ =\"runtime\").text\n",
    "        runtime.append(run)\n",
    "\n",
    "        gen = container.find(\"span\", class_ =\"genre\").text.strip()\n",
    "        genre.append(gen)\n",
    "\n",
    "        content = container.find_all(\"p\")\n",
    "\n",
    "        desc = content[1].text.strip()\n",
    "        tv_show_description.append(desc)\n",
    "\n",
    "        content_2 = content[2].find_all(\"a\")\n",
    "\n",
    "        temp = []\n",
    "        for i in range(len(content_2)):\n",
    "            temp.append(content_2[i].text)\n",
    "        star_cast.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the TV show information into a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_show_df = pd.DataFrame({\"tv_show_name\" :tv_show_names,\n",
    "                        \"tv_show_id\" :title_Id,\n",
    "                        \"start_and_end_year\" :year_release,\n",
    "                        \"imdb_rating\" :imdb_ratings,\n",
    "                        \"votes\" :votes,\n",
    "                        \"tv_show_description\" :tv_show_description,\n",
    "                        \"runtime\" :runtime,\n",
    "                        \"genre\" :genre,\n",
    "                        \"star_cast\": star_cast,\n",
    "                        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the season information of the TV shows; Forming the list to store scraped value data in & doing the variable assignments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_Id = []\n",
    "epi_name = []\n",
    "c1 = []\n",
    "b = []\n",
    "n = []\n",
    "m = []\n",
    "x= []\n",
    "u = []\n",
    "y = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping the season data by looping through the webpage;\n",
    "Generating the URL for the maximum number of seasons to scrape the data from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tv_show_df.iterrows():\n",
    "    x = str(row['tv_show_id'])\n",
    "    url_season = 'https://www.imdb.com/title/' + x + '/?ref_=adv_li_tt'\n",
    "\n",
    "    response = get(url_season)\n",
    "    html_soup = bs(response.text, 'html.parser')\n",
    "\n",
    "    id_check = html_soup.find(id=\"main_bottom\")\n",
    "    episode_container = id_check.find(class_=\"seasons-and-year-nav\")\n",
    "\n",
    "    total_seasons = episode_container.a.text\n",
    "    total_seasons = int(total_seasons)\n",
    "\n",
    "    while y <= total_seasons:\n",
    "        \n",
    "        url = 'https://www.imdb.com/title/' + x + '/episodes?season=' + str(y)\n",
    "        response = get(url)\n",
    "        html_soup = bs(response.text, 'html.parser')\n",
    "        id_check = html_soup.find(id=\"main\")\n",
    "        episode_container = id_check.find_all(class_=\"list_item\")\n",
    "        len(episode_container)\n",
    "        epi_container = episode_container[0]\n",
    "        c = 0\n",
    "        \n",
    "        for epi_container in episode_container:\n",
    "\n",
    "            if epi_container.find(\"div\", class_=\"ipl-rating-widget\") is not None:\n",
    "                \n",
    "                id_1 = epi_container.div.a.find('div', class_=\"hover-over-image\")['data-const']\n",
    "                title_Id.append(id_1)\n",
    "\n",
    "                name = epi_container.a['title']\n",
    "                epi_name.append(name)\n",
    "\n",
    "                c += 1\n",
    "                c1.append(c)\n",
    "\n",
    "        b.extend(title_Id)\n",
    "        n.extend(epi_name)\n",
    "        m.extend(c1)\n",
    "        \n",
    "        title_Id.clear()\n",
    "        epi_name.clear()\n",
    "        c1.clear()\n",
    "        \n",
    "        y += 1\n",
    "        \n",
    "    y = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the season wise information into a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df = pd.DataFrame({\"title_id\": b,\n",
    "                   'episode_name': n,\n",
    "                   'episode_number': m})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the episode details of individual TV shows information;\n",
    "List to store scraped value data in & variable assignments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_name = []\n",
    "duration = []\n",
    "epi_ratings = []\n",
    "votes = []\n",
    "tv_show_name = []\n",
    "director = []\n",
    "season_name = []\n",
    "x = []\n",
    "g = []\n",
    "h = []\n",
    "j = []\n",
    "k = []\n",
    "l = []\n",
    "f = []\n",
    "y = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping the episode data by looping through the webpage;\n",
    "Generating the URL to scrape the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in season_df.iterrows():\n",
    "    x = str(row['title_id'])\n",
    "    y = str(row['episode_number'])\n",
    "    url_1 = 'https://www.imdb.com/title/' + x + '/?ref_=ttep_ep' + y\n",
    "    response = get(url_1)\n",
    "    html_soup = bs(response.text, 'html.parser')\n",
    "    id_check = html_soup.find(id=\"main_top\")\n",
    "    episode_container = id_check.find_all(class_=\"heroic-overview\")\n",
    "    epi_container = episode_container[0]\n",
    "\n",
    "    for epi_container in episode_container:\n",
    "\n",
    "        if epi_container.find(\"div\", class_=\"title_block\") is not None:\n",
    "\n",
    "            name = epi_container.find(class_=\"title_wrapper\").h1.text.strip()\n",
    "            episode_name.append(name)\n",
    "\n",
    "            time = epi_container.find(class_=\"subtext\").time.text.strip()\n",
    "            duration.append(time)\n",
    "\n",
    "            try:\n",
    "                rat = epi_container.find(class_=\"ratingValue\").strong.span.text\n",
    "                epi_ratings.append(rat)\n",
    "            except:\n",
    "                epi_ratings.append('NA')\n",
    "\n",
    "            title = epi_container.find(class_=\"titleParent\").a.text\n",
    "            tv_show_name.append(title)\n",
    "\n",
    "            try:\n",
    "                dir = epi_container.find(class_=\"credit_summary_item\").a.text\n",
    "                director.append(dir)\n",
    "            except:\n",
    "                director.append('NA')\n",
    "\n",
    "            s_name = epi_container.find(class_=\"bp_heading\").text\n",
    "            season_name.append(s_name)\n",
    "\n",
    "    g.extend(episode_name)\n",
    "    h.extend(duration)\n",
    "    f.extend(epi_ratings)\n",
    "    j.extend(tv_show_name)\n",
    "    k.extend(director)\n",
    "    l.extend(season_name)\n",
    "    \n",
    "    episode_name.clear()\n",
    "    duration.clear()\n",
    "    tv_show_name.clear()\n",
    "    director.clear()\n",
    "    season_name.clear()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the episode wise information into a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\"episode_name\": g,\n",
    "     \"tv_show_name\": j,\n",
    "     \"imdb_ratings\": epi_ratings,\n",
    "     \"runtime_in_mins\": h,\n",
    "     \"director\": k,\n",
    "     \"season\": l}\n",
    "\n",
    "episode_df = pd.DataFrame.from_dict(a, orient='index')\n",
    "episode_df = episode_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_df['runtime_in_mins'] = episode_df.runtime_in_mins.str.replace('[^0-9]', '')\n",
    "episode_df['runtime_in_mins'].astype('int64')\n",
    "\n",
    "tv_show_df['runtime'] = tv_show_df.runtime.str.replace('[^0-9]', '')\n",
    "tv_show_df['runtime'].astype('int64')\n",
    "\n",
    "tv_show_df['start_and_end_year'] = tv_show_df.start_and_end_year.str.replace('[^0-9]', ' ')\n",
    "tv_show_df['start_and_end_year'] = tv_show_df.start_and_end_year.str.replace(' ','')\n",
    "\n",
    "tv_show_df['start_year'] = tv_show_df.start_and_end_year.str.slice(0, 4)\n",
    "tv_show_df['end_year'] = tv_show_df.start_and_end_year.str.slice(4, 8)\n",
    "tv_show_df['start_year'].astype('int64')\n",
    "\n",
    "tv_show_df = tv_show_df.drop(columns=['start_and_end_year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_show_df.to_csv('TV_Show_Entity.csv',index=False)\n",
    "episode_df.to_csv('Episode_Entity.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
